{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT CLF 10kGNAD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPAbBAKz/A84jvkdUnTTfD9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f71920fa881244ea85c39409b1b96d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b49347dfe4db46ef919b03c23ecde5c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51e945e640d142c6b90807ee672dbc9e",
              "IPY_MODEL_ffb4062b1ea441418140193d72c32f7b"
            ]
          }
        },
        "b49347dfe4db46ef919b03c23ecde5c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51e945e640d142c6b90807ee672dbc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_453b183a1bab4fd3b23ca63adeb814f3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3d1e5aa30ff45b3994dcfbb00cb5398"
          }
        },
        "ffb4062b1ea441418140193d72c32f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5941b1b469cb4657bcad68ec0cbcc9ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 626B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a5577e997a340f1bea6e395e3c49bbf"
          }
        },
        "453b183a1bab4fd3b23ca63adeb814f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3d1e5aa30ff45b3994dcfbb00cb5398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5941b1b469cb4657bcad68ec0cbcc9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a5577e997a340f1bea6e395e3c49bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e197bc0956e4876b8aa56b8c5255e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_35e9dd339c40458aac07ac35dcda5f73",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20983b36654d49bb9f476b6a8ffa91b5",
              "IPY_MODEL_e99b5bced0cd4d9095d19dc0d0b8a457"
            ]
          }
        },
        "35e9dd339c40458aac07ac35dcda5f73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20983b36654d49bb9f476b6a8ffa91b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5537862d1cb9464186e75ebdabba1442",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 438869143,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 438869143,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_460bea2c7579442ca7f7569f25530569"
          }
        },
        "e99b5bced0cd4d9095d19dc0d0b8a457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aab7e9f633bf4b4da61863113965792f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 439M/439M [00:10&lt;00:00, 42.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5f7fe4ade8646f5a1afa5fcf582547a"
          }
        },
        "5537862d1cb9464186e75ebdabba1442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "460bea2c7579442ca7f7569f25530569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aab7e9f633bf4b4da61863113965792f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5f7fe4ade8646f5a1afa5fcf582547a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "len8Qi91y5FX",
        "colab_type": "code",
        "outputId": "d620c5e2-0831-4b44-8cae-cfd5d5829c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!pip install wget\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QA9w6dbwfzz",
        "colab_type": "text"
      },
      "source": [
        "# BERT Fine Tuning for Multi Class Text Classification \n",
        "\n",
        "This notebook contains code to fine tune a pretrained BERT language model to a specific classification task. \n",
        "As BERT model interface the Huggingface library with a PyTorch backend is used.\n",
        "\n",
        "In this notebook, the model has been fine tuned with the German 10kGNAD Dataset but could easily be fine tuned on any other classification dataset.\n",
        "\n",
        "The code was implemented based on the huggingface example scripts for glue tasks fine tuning (https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128) and the blog post by Chris McCormick (http://mccormickml.com/2019/07/22/BERT-fine-tuning/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKjjVxVDKsS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "65be02af-374b-4641-e39f-ee52a57f9880"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoConfig\n",
        "from transformers import AdamW\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import seaborn as sns\n",
        "import IPython\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhzCltg3tR-q",
        "colab_type": "code",
        "outputId": "bd07901e-4dba-45ab-c79c-c40b1eaa3d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Empty cache of GPU\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZxf_D2gAdTO",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJzGKGLX9AxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/tblock/10kGNAD/master/articles.csv\",\n",
        "                 encoding=\"utf-8\",\n",
        "                 delimiter=\";\",\n",
        "                 quotechar=\"'\", names=[\"label\",\"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuN3olL1s1R0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = df.text.values\n",
        "label_cats = df.label.astype('category').cat\n",
        "\n",
        "# List of label names (str)\n",
        "label_names = label_cats.categories\n",
        "\n",
        "# List of label ids (int, in range (0,num_classes-1))\n",
        "labels = label_cats.codes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSsp_l_yoNJf",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UUTkMV4yDTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"bert-base-german-cased\"\n",
        "MAX_INPUT_LENGTH = 192"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-OE6oDZoMIG",
        "colab_type": "code",
        "outputId": "beafbb73-3083-4bb4-bc99-1e0cb0169c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "f71920fa881244ea85c39409b1b96d4f",
            "b49347dfe4db46ef919b03c23ecde5c5",
            "51e945e640d142c6b90807ee672dbc9e",
            "ffb4062b1ea441418140193d72c32f7b",
            "453b183a1bab4fd3b23ca63adeb814f3",
            "a3d1e5aa30ff45b3994dcfbb00cb5398",
            "5941b1b469cb4657bcad68ec0cbcc9ae",
            "7a5577e997a340f1bea6e395e3c49bbf"
          ]
        }
      },
      "source": [
        "# Load the pretrained BERT tokenizer.\n",
        "print(f\"Loading {model_name} tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading bert-base-german-cased tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f71920fa881244ea85c39409b1b96d4f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDkMb1urrIAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,            \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = MAX_INPUT_LENGTH,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt')\n",
        "  \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBM6SwDHvirL",
        "colab_type": "code",
        "outputId": "0490fa73-7d5e-456f-fc25-8bbaf820c4b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', texts[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Attention Mask:', attention_masks[0]) # 1 for all text tokens, 0 for all padding tokens"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Die ARD-Tochter Degeto hat sich verpflichtet, ab August einer Quotenregelung zu folgen, die für die Gleichstellung von Regisseurinnen sorgen soll. In mindestens 20 Prozent der Filme, die die ARD-Tochter Degeto produziert oder mitfinanziert, sollen ab Mitte August Frauen Regie führen. Degeto-Chefin Christine Strobl folgt mit dieser Selbstverpflichtung der Forderung von Pro Quote Regie. Die Vereinigung von Regisseurinnen hatte im vergangenen Jahr eine Quotenregelung gefordert, um den weiblichen Filmschaffenden mehr Gehör und ökonomische Gleichstellung zu verschaffen. Pro Quote Regie kritisiert, dass, während rund 50 Prozent der Regie-Studierenden weiblich seien, der Anteil der Regisseurinnen bei Fernsehfilmen nur bei 13 bis 15 Prozent liege. In Österreich sieht die Situation ähnlich aus, auch hier wird von unterschiedlichen Seiten Handlungsbedarf angemahnt. Aber wie soll dieser aussehen? Ist die Einführung der Quotenregelung auch für die österreichische Film- und Fernsehlandschaft sinnvoll? Diskutieren Sie im Forum.\n",
            "Token IDs: tensor([    3,   125,  9986, 26935,  2394,   576,  3736, 26910,   193,   144,\n",
            "         3983, 26918,   281,  1205,   225, 22385, 12198,   640,    77,    27,\n",
            "           81,  4974, 26918,    30,   142,    30,  2544,   859,    88,  6791,\n",
            "         1443,  9103,   459, 26914,   173,  3451,   148,  1028,    21,  8215,\n",
            "        26918,    30,    30,  9986, 26935,  2394,   576,  3736, 26910,  7042,\n",
            "          309,   114,  6548,   321, 26918,  1922,   281,  2176,  1205,  1895,\n",
            "         7142,  2894, 26914,   576,  3736, 26910, 26935,  3913,    14, 17715,\n",
            "        21252,   693,  2872,   114,   534, 17876, 15469,    21,  7729,    88,\n",
            "          314, 22385,  7142, 26914,   125,  9172,    88,  6791,  1443,   466,\n",
            "          106,  2512,   203,   155, 22385, 12198,   640,    77,    27, 10503,\n",
            "        26918,   259,    86, 15765,  8550,     8,  1886,    65,   380, 12798,\n",
            "           42, 13502,   262,  2544,   859,    81, 16639, 26914,   314, 22385,\n",
            "         7142,  9169, 26918,   221, 26918,  1195,  1521,  2186,  1028,    21,\n",
            "         7142, 26935, 18267,  7556,    68,  1196, 26918,    21,  4566,    21,\n",
            "         6791,  1443,   178,  3647, 18409,   356,   178,   857,   255,   659,\n",
            "         1028,  8037, 26914,   173,  2661,  2648,    30,  4344,  5677,   147,\n",
            "        26918,   194,   702,   292,    88,  8317,     7,  2530, 10962,  8869,\n",
            "        11837, 19249, 26914,  1882,   246,   459,   534, 15930, 26972,  4352,\n",
            "           30,  6165,    21, 22385, 12198,   640,    77,    27,   194,   142,\n",
            "           30,     4])\n",
            "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO3MaaVkuI-c",
        "colab_type": "code",
        "outputId": "23c1d614-c3ec-4c9b-bfa8-9fe54f72d3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 80-10-10 train-validation-test split\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset)) \n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print(f\"{train_size} training samples\")\n",
        "print(f\"{val_size} validation samples\")\n",
        "print(f\"{test_size} test samples\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8218 training samples\n",
            "1027 validation samples\n",
            "1028 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiHoD0KoNpZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# For test the order doesn't matter, so we'll just read them sequentially.\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            sampler = SequentialSampler(test_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1IY9cwiAUCZ",
        "colab_type": "text"
      },
      "source": [
        "## Create and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWfvlMlBg-3_",
        "colab_type": "code",
        "outputId": "baf89995-1257-4da1-c2e0-a311dd9951aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7e197bc0956e4876b8aa56b8c5255e10",
            "35e9dd339c40458aac07ac35dcda5f73",
            "20983b36654d49bb9f476b6a8ffa91b5",
            "e99b5bced0cd4d9095d19dc0d0b8a457",
            "5537862d1cb9464186e75ebdabba1442",
            "460bea2c7579442ca7f7569f25530569",
            "aab7e9f633bf4b4da61863113965792f",
            "f5f7fe4ade8646f5a1afa5fcf582547a"
          ]
        }
      },
      "source": [
        "# Load pretrained model for sequence classification\n",
        "print(f\"Loading {model_name} model...\")\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "config.num_labels = len(label_names)\n",
        "config.output_attentions = True\n",
        "print(\"config\", config)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    config=config)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading bert-base-german-cased model...\n",
            "config BertConfig {\n",
            "  \"_num_labels\": 9,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": true,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e197bc0956e4876b8aa56b8c5255e10",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=438869143, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIBG_g36utJA",
        "colab_type": "code",
        "outputId": "979eff33-7f8c-4286-8c54-7bd99e36adb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30000, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (9, 768)\n",
            "classifier.bias                                                 (9,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzojbxacu1ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFeBj0EhyGlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs5ImW58hZ4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbwgopNUhm-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub1-0NFChoc6",
        "colab_type": "code",
        "outputId": "010ccfd3-dd29-4f0a-c96d-6ac2148cfc0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits, attentions = model(input_ids=b_input_ids, \n",
        "                                         attention_mask=b_input_mask, \n",
        "                                         labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits, attentions) = model(input_ids=b_input_ids, \n",
        "                                               attention_mask=b_input_mask,\n",
        "                                               labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    514.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    514.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    514.    Elapsed: 0:00:38.\n",
            "  Batch   160  of    514.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    514.    Elapsed: 0:01:03.\n",
            "  Batch   240  of    514.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    514.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    514.    Elapsed: 0:01:40.\n",
            "  Batch   360  of    514.    Elapsed: 0:01:52.\n",
            "  Batch   400  of    514.    Elapsed: 0:02:05.\n",
            "  Batch   440  of    514.    Elapsed: 0:02:17.\n",
            "  Batch   480  of    514.    Elapsed: 0:02:30.\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Training epoch took: 0:02:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.40\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    514.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    514.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    514.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    514.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    514.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    514.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    514.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    514.    Elapsed: 0:01:40.\n",
            "  Batch   360  of    514.    Elapsed: 0:01:52.\n",
            "  Batch   400  of    514.    Elapsed: 0:02:05.\n",
            "  Batch   440  of    514.    Elapsed: 0:02:17.\n",
            "  Batch   480  of    514.    Elapsed: 0:02:30.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epoch took: 0:02:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation Loss: 0.37\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    514.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    514.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    514.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    514.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    514.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    514.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    514.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    514.    Elapsed: 0:01:40.\n",
            "  Batch   360  of    514.    Elapsed: 0:01:52.\n",
            "  Batch   400  of    514.    Elapsed: 0:02:05.\n",
            "  Batch   440  of    514.    Elapsed: 0:02:17.\n",
            "  Batch   480  of    514.    Elapsed: 0:02:29.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epoch took: 0:02:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.44\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:08:19 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxik8IiPhvXC",
        "colab_type": "code",
        "outputId": "b355dc55-7551-43e5-97ef-63de087c8157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:02:40</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.24</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0:02:40</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0:02:40</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.60         0.40           0.87       0:02:40         0:00:06\n",
              "2               0.24         0.37           0.89       0:02:40         0:00:06\n",
              "3               0.11         0.44           0.90       0:02:40         0:00:06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2G-EegN85iC",
        "colab_type": "code",
        "outputId": "e254888a-120b-4fde-86ba-d67f04fb9c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWmaN_QFZKvd",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhhTNEe2ZQM-",
        "colab_type": "code",
        "outputId": "56f84964-e680-47ef-869e-db43203f39ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print(\"Predicting labels ...\")\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in test_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(input_ids=b_input_ids,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.extend(logits)\n",
        "  true_labels.extend(label_ids)\n",
        "\n",
        "print(f\"Predicted {len(predictions)} samples\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels ...\n",
            "Predicted 1028 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htdXUiYk7fyB",
        "colab_type": "code",
        "outputId": "3785b29b-3444-43d8-da88-143488a17fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "predictions = np.argmax(predictions, axis=1)\n",
        "print(f\"Test set accuracy: {accuracy_score(true_labels, predictions)}\")\n",
        "print(f\"Test set Matthews correlation coefficient: {matthews_corrcoef(true_labels, predictions)}\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set accuracy: 0.9105058365758755\n",
            "Test set Matthews correlation coefficient: 0.8972096756251449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5EStuaZBGLk",
        "colab_type": "text"
      },
      "source": [
        "## Save model to disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZIqwQvuBKFZ",
        "colab_type": "code",
        "outputId": "45603805-cb31-4e71-bc58-2d24888b7bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = f\"./{model_name}/\"\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(f\"Saving model to {output_dir}\")\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "#torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./bert-base-german-cased/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./bert-base-german-cased/vocab.txt',\n",
              " './bert-base-german-cased/special_tokens_map.json',\n",
              " './bert-base-german-cased/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le22WIOxhSaj",
        "colab_type": "code",
        "outputId": "1b91b045-6845-4ab1-993c-dfe2f1cd767f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaXz2CrQhVyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "target_dir = f\"\\\"./drive/My Drive/NLP/BERT CLF 10kGNAD/\\\"\"\n",
        "!cp -r $output_dir $target_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tXFWVdxh7Zd",
        "colab_type": "text"
      },
      "source": [
        "## Load Model from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94-4pMG-h_G_",
        "colab_type": "code",
        "outputId": "777d9dcb-064a-48aa-8ed0-b1aa2cb25b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "output_dir = f\"./drive/My Drive/NLP/BERT CLF 10kGNAD/{model_name}/\"\n",
        "\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = AutoModelForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT525N9VbR8n",
        "colab_type": "text"
      },
      "source": [
        "## Predict on some sample text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI_uBpaWxZaY",
        "colab_type": "text"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esq849IYbVj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = [\"Heldt hätte kein Problem damit, wenn es in zwei Wochen in der Bundesliga wieder losgehen würde. „Wir lernen gerade alle, Kompromisse einzugehen, an die wir vor Wochen noch nicht gedacht haben.“ Natürlich seien zehn bis 14 Tage richtiges Mannschaftstraining sinnvoll. „Aber vielleicht kriegen wir diese Zeit nicht. Und dann machen wir es so“, ergänzte der langjährige Manager. Köln-Profi Birger Verstraete hält die Maßnahmen nach den drei positiven Corona-Tests derweil für leichtsinnig. „Wir sollten vorerst nicht unter Quarantäne gestellt werden, und das ist ein bisschen bizarr“, sagte der belgische Mittelfeldspieler dem TV-Sender „VTM“. Beim 1. FC Köln waren zwei Spieler und ein Betreuer positiv auf das Coronavirus getestet worden. „Der Physiotherapeut ist der Mann, der mich und andere Spieler wochenlang behandelt hat. Und mit einem der beiden fraglichen Spieler habe ich am Donnerstag im Fitnessstudio ein Duo gebildet“, sagte Verstraete in dem Interview, über das „Het Laatste Nieuws berichtete.\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2PSbpD9bcqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in texts:\n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "                          text,            \n",
        "                          add_special_tokens = True,\n",
        "                          max_length = 64,\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,\n",
        "                          return_tensors = 'pt')\n",
        "  \n",
        "  # Add the encoded sentence to the list.    \n",
        "  input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "  # And its attention mask (simply differentiates padding from non-padding).\n",
        "  attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBv57F46cKST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "last_layer_attentions = []\n",
        "\n",
        "# Move input ids and attention masks to GPU\n",
        "input_ids = input_ids.to(device)\n",
        "attention_masks = attention_masks.to(device)\n",
        "\n",
        "for i in range(len(input_ids)):\n",
        "\n",
        "  ids = input_ids[i].unsqueeze(0)\n",
        "  masks = attention_masks[i].unsqueeze(0)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(input_ids=ids,\n",
        "                      attention_mask=masks)\n",
        "\n",
        "  # Get logits and compute softmax\n",
        "  logits = outputs[0]\n",
        "  logits = torch.softmax(logits,dim=1)\n",
        "  last_layer_attention = outputs[1][-1]\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  last_layer_attention = last_layer_attention.detach().cpu().numpy()\n",
        "\n",
        "  last_layer_attentions.append(last_layer_attention)\n",
        "  predictions.append(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8t_Ygply0X3",
        "colab_type": "code",
        "outputId": "358e0eba-eda2-4a6f-cac5-58bce5169187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "probs = predictions[0][0]\n",
        "print(\"text:\", texts[0])\n",
        "print(\"predictions:\", probs)\n",
        "pred_idx = np.argmax(probs)\n",
        "print(f\"Prediction: {label_names[pred_idx]} ({probs[pred_idx]:.2f})\", )"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text: Heldt hätte kein Problem damit, wenn es in zwei Wochen in der Bundesliga wieder losgehen würde. „Wir lernen gerade alle, Kompromisse einzugehen, an die wir vor Wochen noch nicht gedacht haben.“ Natürlich seien zehn bis 14 Tage richtiges Mannschaftstraining sinnvoll. „Aber vielleicht kriegen wir diese Zeit nicht. Und dann machen wir es so“, ergänzte der langjährige Manager. Köln-Profi Birger Verstraete hält die Maßnahmen nach den drei positiven Corona-Tests derweil für leichtsinnig. „Wir sollten vorerst nicht unter Quarantäne gestellt werden, und das ist ein bisschen bizarr“, sagte der belgische Mittelfeldspieler dem TV-Sender „VTM“. Beim 1. FC Köln waren zwei Spieler und ein Betreuer positiv auf das Coronavirus getestet worden. „Der Physiotherapeut ist der Mann, der mich und andere Spieler wochenlang behandelt hat. Und mit einem der beiden fraglichen Spieler habe ich am Donnerstag im Fitnessstudio ein Duo gebildet“, sagte Verstraete in dem Interview, über das „Het Laatste Nieuws berichtete.\n",
            "predictions: [1.0679949e-03 8.8444026e-04 3.8669645e-03 1.7328591e-03 7.7026529e-04\n",
            " 9.8628575e-01 9.4877667e-04 3.0755729e-03 1.3673912e-03]\n",
            "Prediction: Sport (0.99)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi9mhLaryMNS",
        "colab_type": "code",
        "outputId": "da989ec5-5025-4677-8d85-76995910a966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "fig = plt.figure(tight_layout=True)\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "y_pos = np.arange(len(label_names))\n",
        "confidences = [probs[i] for i in range(len(label_names))]\n",
        "\n",
        "ax.barh(y_pos, confidences, align='center')\n",
        "ax.set_yticks(y_pos)\n",
        "ax.set_yticklabels(label_names)\n",
        "ax.invert_yaxis()  # labels read top-to-bottom\n",
        "ax.set_xlabel('Confidence')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofcRyMHTxh_f",
        "colab_type": "text"
      },
      "source": [
        "### Visualize Attentions\n",
        "\n",
        "For each token, visualize the average over all 12 heads of the last layer's attention to the special character [CLS]. The darker the background of the token, the higher its attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3r6jQpFKWWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lla = last_layer_attentions[0][0][:,0,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDiU0fPDTgkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def avg_token_attentions(last_layer_attentions):\n",
        "  return last_layer_attentions.mean(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iYtEu5vhJPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_token_atts = avg_token_attentions(lla)\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpp6Q3EHoovo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def handle_special_token_attentions(tokens, avg_token_atts):\n",
        "  new_tokens = []\n",
        "  new_avg_token_atts = []\n",
        "  for i in range(len(tokens)):\n",
        "    if tokens[i].startswith(\"[\") or tokens[i].startswith(\"##\"):\n",
        "      continue\n",
        "    if i < tokenizer.max_len - 1 and tokens[i+1].startswith(\"##\"):\n",
        "      merged_tokens = tokens[i] + tokens[i+1][2:]\n",
        "      atts = [avg_token_atts[i], avg_token_atts[i+1]]\n",
        "      i += 1\n",
        "      while i < tokenizer.max_len - 1 and tokens[i+1].startswith(\"##\"):\n",
        "        merged_tokens += tokens[i+1][2:]\n",
        "        atts.append(avg_token_atts[i+1])\n",
        "        i += 1\n",
        "      new_tokens.append(merged_tokens)\n",
        "      new_avg_token_atts.append(sum(atts)/len(atts))\n",
        "    elif i < tokenizer.max_len - 1:\n",
        "      new_tokens.append(tokens[i])\n",
        "      new_avg_token_atts.append(avg_token_atts[i])\n",
        "  new_avg_token_atts = new_avg_token_atts / sum(new_avg_token_atts)\n",
        "  return new_tokens, new_avg_token_atts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC7Y8NcVq3w3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens, avg_token_atts = handle_special_token_attentions(tokens, avg_token_atts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrCl0RbXmu2W",
        "colab_type": "code",
        "outputId": "c616553f-624b-4e16-9c6f-019795991521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "for token, att in zip(tokens, avg_token_atts):\n",
        "  print(token, att)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Heldt 0.05963272150050977\n",
            "hätte 0.05842705044356964\n",
            "kein 0.015847744346937087\n",
            "Problem 0.01636351010862091\n",
            "damit 0.013772409461545421\n",
            ", 0.036807565532129716\n",
            "wenn 0.03087712355309333\n",
            "es 0.024819269697866908\n",
            "in 0.018017946361961145\n",
            "zwei 0.017895302157496278\n",
            "Wochen 0.03003063986432607\n",
            "in 0.025940210667872093\n",
            "der 0.023251029511036282\n",
            "Bundesliga 0.05716164042458836\n",
            "wieder 0.01203980647078767\n",
            "losgehen 0.00583129451285671\n",
            "würde 0.03879455071515468\n",
            ". 0.12072620863387562\n",
            "Wir 0.019060273146967795\n",
            "lernen 0.012353933512564218\n",
            "gerade 0.00628229120688047\n",
            "alle 0.010505001215702199\n",
            ", 0.012323023127170943\n",
            "Kompromisse 0.0056848631707390965\n",
            "einzugehen 0.002722717941780326\n",
            ", 0.005047595520602355\n",
            "an 0.0018329884443071581\n",
            "die 0.0032613291405828838\n",
            "wir 0.013254898654295608\n",
            "vor 0.0036984695310786435\n",
            "Wochen 0.013122986397435385\n",
            "noch 0.001867398487968193\n",
            "nicht 0.0013720230891756517\n",
            "gedacht 0.0011624416595517478\n",
            "haben 0.005847323292139942\n",
            ". 0.0359342915081955\n",
            "Natürlich 0.0063752301906867415\n",
            "seien 0.011021791396847837\n",
            "zehn 0.004314394078787275\n",
            "bis 0.010067432806270381\n",
            "14 0.00470361136148839\n",
            "Tage 0.007221872841094629\n",
            "richtiges 0.006858679639577968\n",
            "Mannschaftstraining 0.027314170292516007\n",
            "sinnvoll 0.00564797832983223\n",
            ". 0.02234715007256007\n",
            "Aber 0.014534143045985954\n",
            "vielleicht 0.02090649367599008\n",
            "kriegen 0.023371325204447596\n",
            "wir 0.023200140591150317\n",
            "diese 0.050545713461398724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa9tlNnqvgm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale_color_h_hex(c_h, scale):\n",
        "    return matplotlib.colors.to_hex(\n",
        "        matplotlib.colors.hsv_to_rgb((c_h, scale, 1)))\n",
        "\n",
        "def blue_background_hex(scale):\n",
        "    return scale_color_h_hex(0.625, scale)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js7LWFLMxoeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "att_html = \"<table><tr>\"\n",
        "for token, att in zip(tokens, avg_token_atts):\n",
        "  att_html += \"<td>\"\n",
        "  att_html += \"<span style=\\\"background-color: \" + blue_background_hex(att) + \"\\\">\" + token + \"</span>\"\n",
        "  att_html += \"</td>\"\n",
        "att_html += \"</tr>\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybnrhz1mzfw1",
        "colab_type": "code",
        "outputId": "1d8d6735-0f1d-484d-efbc-baacd728ea83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 60
        }
      },
      "source": [
        "IPython.display.HTML(att_html) "
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table><tr><td><span style=\"background-color: #f0f4ff\">Heldt</span></td><td><span style=\"background-color: #f0f4ff\">hätte</span></td><td><span style=\"background-color: #fbfcff\">kein</span></td><td><span style=\"background-color: #fbfcff\">Problem</span></td><td><span style=\"background-color: #fbfcff\">damit</span></td><td><span style=\"background-color: #f6f8ff\">,</span></td><td><span style=\"background-color: #f7f9ff\">wenn</span></td><td><span style=\"background-color: #f9faff\">es</span></td><td><span style=\"background-color: #fafcff\">in</span></td><td><span style=\"background-color: #fafcff\">zwei</span></td><td><span style=\"background-color: #f7f9ff\">Wochen</span></td><td><span style=\"background-color: #f8faff\">in</span></td><td><span style=\"background-color: #f9fbff\">der</span></td><td><span style=\"background-color: #f0f4ff\">Bundesliga</span></td><td><span style=\"background-color: #fcfdff\">wieder</span></td><td><span style=\"background-color: #fefeff\">losgehen</span></td><td><span style=\"background-color: #f5f8ff\">würde</span></td><td><span style=\"background-color: #e0e8ff\">.</span></td><td><span style=\"background-color: #fafbff\">Wir</span></td><td><span style=\"background-color: #fcfdff\">lernen</span></td><td><span style=\"background-color: #fdfeff\">gerade</span></td><td><span style=\"background-color: #fcfdff\">alle</span></td><td><span style=\"background-color: #fcfdff\">,</span></td><td><span style=\"background-color: #fefeff\">Kompromisse</span></td><td><span style=\"background-color: #fefeff\">einzugehen</span></td><td><span style=\"background-color: #fefeff\">,</span></td><td><span style=\"background-color: #ffffff\">an</span></td><td><span style=\"background-color: #fefeff\">die</span></td><td><span style=\"background-color: #fcfcff\">wir</span></td><td><span style=\"background-color: #fefeff\">vor</span></td><td><span style=\"background-color: #fcfcff\">Wochen</span></td><td><span style=\"background-color: #ffffff\">noch</span></td><td><span style=\"background-color: #ffffff\">nicht</span></td><td><span style=\"background-color: #ffffff\">gedacht</span></td><td><span style=\"background-color: #fefeff\">haben</span></td><td><span style=\"background-color: #f6f8ff\">.</span></td><td><span style=\"background-color: #fdfeff\">Natürlich</span></td><td><span style=\"background-color: #fcfdff\">seien</span></td><td><span style=\"background-color: #fefeff\">zehn</span></td><td><span style=\"background-color: #fcfdff\">bis</span></td><td><span style=\"background-color: #fefeff\">14</span></td><td><span style=\"background-color: #fdfeff\">Tage</span></td><td><span style=\"background-color: #fdfeff\">richtiges</span></td><td><span style=\"background-color: #f8faff\">Mannschaftstraining</span></td><td><span style=\"background-color: #fefeff\">sinnvoll</span></td><td><span style=\"background-color: #f9fbff\">.</span></td><td><span style=\"background-color: #fbfcff\">Aber</span></td><td><span style=\"background-color: #fafbff\">vielleicht</span></td><td><span style=\"background-color: #f9fbff\">kriegen</span></td><td><span style=\"background-color: #f9fbff\">wir</span></td><td><span style=\"background-color: #f2f5ff\">diese</span></td></tr>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJLGG1jmzszh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}